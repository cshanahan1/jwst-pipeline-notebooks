{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the JWST pipeline\n",
    "\n",
    "#### This is a tutorial on running the JWST Science Calibration Pipeline (referred to as “the pipeline”).\n",
    "\n",
    "## Pre-notebook setup: <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "Before going through the examples in this notebook, complete the following setup steps.\n",
    "\n",
    "1. This tutorial assumes a user has [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) installed for package and environment management. For the purpose of this tutorial we will install JWST in a new conda environment named `jwst-test`, using Python 3.8. The JWST package installs its dependencies but we need to install Python and numpy in this conda environment.\n",
    "\n",
    "- #### Make and activate the new conda environment\n",
    "\n",
    "    *% conda create -n jwst-test python=3.8*\n",
    "\n",
    "    *% source activate jwst-test*\n",
    "\n",
    "- #### Install numpy\n",
    "\n",
    "    *% pip install numpy==1.19*\n",
    "\n",
    "- #### Install jupyter (for ipython and jupyter notebooks).\n",
    "\n",
    "    *% pip install jupyter*\n",
    "\n",
    "    After you create the conda environment and install the packages, exit and reopen this notebook, ensuring that you have the new environment activated.\n",
    "\n",
    "\n",
    "2. The examples in this notebook use sample data and reference/parameter files. Before attempting any examples in this notebook, download the contents of LINK_TO_BOX to the directory containing this notebook.\n",
    "\n",
    "\n",
    "3. CRDS, the management system for the reference and parameter files that the pipeline requires, needs to have certain environment variables set to know which server to connect to to download these files, and a local directory. In your shell:\n",
    "\n",
    "    *% export CRDS_PATH=$HOME/crds_cache*\n",
    "\n",
    "    *% export CRDS_SERVER_URL=https://jwst-crds.stsci.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC:\n",
    "\n",
    "* [Overview of JWST Pipeline](#1)\n",
    "    * [What is the JWST Pipeline?](#1a)\n",
    "    * [Reference Files and CRDS](#1b)\n",
    "    * [Parameter Files](#1c)\n",
    "* [Installation](#2)\n",
    "    * [Installing the Last Released Verion of JWST](#2a)\n",
    "    * [Installing the Latest Development Version from Github](#2b)\n",
    "* [Running the Pipeline in Python](#3)\n",
    "    * [Overview of Running the Pipeline in Python](#3a)\n",
    "    * [Example 1: Running a Full Pipeline in Python](#3b)\n",
    "    * [Example 2: Running a Single Pipeline Step in Python](#3c)\n",
    "    * [Options when Running the Pipeline in Python: 'call' vs 'run' Methods](#3d)\n",
    "        * [Example 3: Using `run` Instead of `call` ](#3da)\n",
    "    * [Configuring the Pipeline in Python](#3e)\n",
    "        * [Setting Parameters](#3f)\n",
    "            * [Option 1: Using a Custom or Modified Parameter File (Reccomended)](#3f1)\n",
    "            * [Option 2: Setting Parameters as Attributes on a Pipeline/Step Directly](#3f2)\n",
    "            * [Option 3: Setting Parameters via Dictionary when Using the `call` Method](#3f3)\n",
    "            * [More on Configuring Parameters in Python](#3f4)\n",
    "        * [Changing Reference Files](#3g)\n",
    "            * [Option 1: Overriding Reference Files as an Argument to A Pipeline/Step](#3g1)\n",
    "            * [Option 2: Overriding Reference Files on a Pipeline/Step Directly](#3g2)\n",
    "        * [Skipping Steps](#3h)\n",
    "            * [Option 1: Specifying Pipeline Steps to Skip within a Parameter File](#3h1)\n",
    "            * [Option 2: Skipping Steps Directly when using 'run'](#3h2)\n",
    "* [Running the Pipeline with the Command Line Interface (CLI)](#4)\n",
    "    * [Example 3: Running a Full Pipeline using the CLI](#4a)\n",
    "    * [Example 4: Running a Single Pipeline Step using the CLI](#4b)\n",
    "    * [Configuring the Pipeline using the Command Line Interface](#4c)\n",
    "        * [Setting Parameters](#4d)\n",
    "        * [Changing Reference Files](#4e)\n",
    "        * [Skipping Steps](#4f)\n",
    "    * [Additional Command Line Functionality](#4g)\n",
    "* [FAQ](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of JWST Pipeline <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "The following will provide a very brief summary to provide context for some of the information in this notebook: a more extensive description is available in the [JWST pipeline documentation](https://jwst-pipeline.readthedocs.io/en/latest/).\n",
    "\n",
    "## What is the JWST Pipeline? <a class=\"anchor\" id=\"1a\"></a>\n",
    "\n",
    "The JWST pipeline is the software suite that processes raw data from the JWST instruments to make it science-ready by performing various corrections and operations on the data. The pipeline is written in Python and hosted on [Github]((https://github.com/spacetelescope/jwst).\n",
    "\n",
    "Data products available for download in the MAST archive have already been processed with this pipeline, but users wishing to do custom processing may want to configure and run them pipeline themselves. The pipeline can be ran and configured in [Python](#3) or via the [command line interface](#4) `strun`.\n",
    "\n",
    "The JWST pipeline is broken into 3 [stages](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/main.html). Each stage consists of a series of steps. \n",
    "\n",
    "- Stage 1: Detector-level corrections and ramp fitting for individual exposures\n",
    "\n",
    "  The first stage, called `calwebb_detector1`, is applied nearly universally for all instruments and modes. It consists of detector-level corrections that are performed on a group-by-group basis, followed by ramp fitting. The output of stage 1 processing is a countrate image per exposure, or per integration for some modes. The input to this step is `uncal.fits` file, and the output is a `rate.fits` file.\n",
    "\n",
    "\n",
    "- Stage 2: Instrument-mode calibrations for individual exposures\n",
    "\n",
    "  The second stage is split into separate modules for imaging and spectroscopic data, called `calwebb_image2` and `calwebb_spec2` respectively. It consists of additional instrument-level and observing-mode corrections and calibrations to produce fully calibrated exposures. The details differ for imaging and spectroscopic exposures, and there are some corrections that are unique to certain instruments or modes. The input to this step is `rate.fits` file, and the output is a `cal.fits` file.\n",
    "  \n",
    "  \n",
    "- Stage 3: Combining data from multiple exposures within an observation\n",
    "\n",
    "  The third stage is divided into five separate modules depending on the observing mode. It consists of routines that work with multiple exposures and in most cases produce some kind of combined product. There are unique pipeline modules for stage 3 processing of imaging, spectroscopic, coronagraphic, AMI, and TSO observations.\n",
    "  \n",
    "Each dataset, depending on what type of observation it is, will have three stages in its pipeline. Furthermore, each pipeline consists of individual Steps (e.g `AssignWCSStep`, `LinearityStep`). The modular nature of the pipeline allows users to customize their processing by running the full pipeline, a single stage, a single step within each stage, etc. Steps can also be 'switched' on and off during processing (for example, running the `Detector1Pipeline` but omitting the `DarkCurrentStep`).\n",
    "  \n",
    "All pipelines and steps have parameters that can be set to change various aspects of how they execute.The main way in which the pipeline is configured is via `Parameter Files`. `Reference Files` provide the data for the multitude of calibrations and corrections performed by the pipeline. Both reference files and parameter files can be customized when running the pipeline.\n",
    "\n",
    "## Reference Files and CRDS <a class=\"anchor\" id=\"1b\"></a>\n",
    "\n",
    "Reference files are data files - seperate from the input data being processed - that the JWST pipeline requires to calibrate data and apply necessary corrections and calibrations to achieve science-ready data. An example of a reference file is a dark-current correction file, which is an array that represents the estimated dark-current for each pixel in an image. Each data set has a specific set of up-to-date reference files associated with it which supply the data for all the pipeline calibration steps.\n",
    "\n",
    "Reference files are created and validated by the JWST instrument teams. Because many of these corrections are time dependent (e.g a monthly dark file), or are periodically updated and improved as understanding of the instrument improves, they must be version controlled to ensure users can access the exact set of files for a dataset as well as revert back to previous versions if needed. Managing these files and determining the exact set of reference files to apply to any given data file is not a trivial task: the CRDS (Calibration Reference Data System) manages these intricacies and is the interface for obtaining and managing pipeline reference files.\n",
    "\n",
    "Users internal to the STScI network already have all reference files on disk in the CRDS file system on central storage and will not have to do any special setup to allow the pipeline access to reference files. External users will have to configure their environment to point to the CRDS_SERVER_URL (to download reference files from this server) as well as a directory in their local filesystem (CRDS_PATH) to which these files will be downloaded to, and which the pipeline will recognize as the location of these files when run (this should have been done in the [pre-notebook setup](#0)) In your shell, set the environment variables:\n",
    "\n",
    "##### *% export CRDS_PATH=$HOME/crds_cache*\n",
    "\n",
    "##### *% export CRDS_SERVER_URL=https://jwst-crds.stsci.edu*\n",
    "\n",
    "When you run the pipeline on a dataset for the first time, the CRDS code within the pipeline will determine the best set of reference files based on the exposure date, observation parameters (e.g instrument type and mode, filter), and 'context' (akin to a snapshot in time, the most up-to-date being the default, but users can also roll back to a previous context with different mappings). Then, it will connect to the server (specified via `CRDS_SERVER_URL`) and download those files to your local directory `CRDS_PATH`. Subsequent runs of the Python will first check `CRDS_PATH` for existing required reference files so they aren't re-downloaded. \n",
    "\n",
    "### Parameter Files <a class=\"anchor\" id=\"1b\"></a>\n",
    "Parameter files are [ASDF](https://readthedocs.org/projects/asdf/) format files that set the multitude of parameters for pipeline steps, and are the main way that the JWST pipeline is configured. They are similar to reference files in the sense that they are created by JWST instrument teams and direct the pipeline behavior/output. Also like reference files, they are version controlled and managed by CRDS. This version-controlling gives the instrument teams the ability to evolve parameter values for different observing modes over time.\n",
    "\n",
    "An example of a parameter file is:\n",
    "\n",
    "        >> jwst_miri_pars-detector1pipeline_0001.asdf\n",
    "\n",
    "When a user runs the pipeline, the corresponding parameter files for the step(s) being run and the dataset being processed will be downloaded to the local crds cache (CRDS_PATH) along side the other reference files. \n",
    "\n",
    "Note that not every observing mode/pipeline step have a parameter file - in some cases, there are no special parameter selections needed and the coded defaults suffice. For example, the `Image2Pipeline` for Nircam does not have a parameter file, and the coded default values are used for every dataset. See the [JWST CRDS website](https://jwst-crds.stsci.edu/) to browse parameter files for different steps and observing modes.\n",
    "\n",
    "Parameter files may be ignored or overridden when running the pipeline. Users can override parameters individually, or supply their own custom parameter file which will override keywords in any parameter file existing in CRDS for that dataset. See \\<link> for more information on configuring the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation <a class=\"anchor\" id=\"2\"></a>\n",
    "## Installing the Last Released Verion of JWST<a class=\"anchor\" id=\"2a\"></a>\n",
    "The latest public release can be installed with one command.\n",
    "\n",
    "*% pip install jwst*\n",
    "## Installing the Latest Development Version from Github<a class=\"anchor\" id=\"2b\"></a>\n",
    "To work with the absolute most up-to-date version of the pipeline, the `main` branch of the Github repository can be installed. The source code for the JWST pipeline is located on Github in the spacetelescope organization.\n",
    "\n",
    "https://github.com/spacetelescope/jwst\n",
    "\n",
    "To install the latest code from github use the command:\n",
    "\n",
    "*% pip install git+https://github.com/spacetelescope/jwst*\n",
    "\n",
    "Make sure to keep this install up-to-date because the state of this branch changes on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Pipeline in Python <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "## Overview of Running the Pipeline in Python <a class=\"anchor\" id=\"3a\"></a>\n",
    "\n",
    "All pipelines and steps are avaiable to import and run in a Python session, for example:\n",
    "\n",
    "`from jwst.pipeline import Image3Pipeline`\n",
    "\n",
    "or \n",
    "\n",
    "`from jwst.dark_current import DarkCurrentStep`\n",
    "\n",
    "As will be demonstrated in the examples below, once imported these pipelines and steps can be configured either via parameter files or on the Python object directly, and run on input data files specified by path (or loaded into memory as `DataModels`).\n",
    "\n",
    "## Example 1: Running a Full Pipeline in Python <a class=\"anchor\" id=\"3b\"></a>\n",
    "In this example, the `Detector1Pipeline` will be run with all default parameters and reference files (as determined by CRDS) on a NIRCAM image. The file for this example is an `uncal` file, which is the naming convention for file yet to undergo any pipeline corrections.\n",
    "\n",
    "First, import the desired pipeline (in this case Detector1Pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.pipeline import Detector1Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next, the basic call to run the pipeline, using the `call` method with the input file as an argument.\n",
    "\n",
    "By default, the final correction is returned in-memory only (though outputs from intermediate steps may be saved as output files). This can be changed by setting the optional `save_results` argument to True in the call. In this example, we will choose to write out the file and also to assign the output, which is a `DataModel` (an object representing the entire fits file), to the variable `result` so that the result of the pipeline is available immediatley in memory.\n",
    "\n",
    "You will notice that while running the pipeline, there is informative logging information printed to the screen and in this instance, you'll also see the file `jw42424001001_01101_00001_nrca5_trapsfilled.fits` output in the cwd - this is an intermediate output from the [persistance](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/nonscience_products.html#charge-trap-state-data-trapsfilled) step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = Detector1Pipeline.call('jw42424001001_01101_00001_nrca5_uncal.fits', save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibrated data model `result` contains information about how the pipeline was run - for example, you can see in `model.meta.cal_step` which steps were run (COMPLETE) and which were not (SKIPPED)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also inspect the names of the reference files that were used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Running a Single Pipeline Step in Python <a class=\"anchor\" id=\"3c\"></a>\n",
    "\n",
    "In the first example, the full Detector1Pipeline was run on the input `uncal` date. We can run the steps that comprise this pipeline individually, for example, the `LinearityStep`. Running a pipeline step is done in the exact same way: import the step and use the `call` method with your data as input. In this case, we will not set `save_results` to True so no intermediate output will be written, only a `DataModel` with `LinearityStep` will be returned in memory to the variable `lin_corr_im`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:31,539 - stpipe.LinearityStep - INFO - LinearityStep instance created.\n"
     ]
    }
   ],
   "source": [
    "from jwst.linearity import LinearityStep\n",
    "\n",
    "step = LinearityStep()\n",
    "\n",
    "#lin_corr_im = step.call('jw42424001001_01101_00001_nrca5_uncal.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options when Running the Pipeline in Python: 'call' vs 'run' Methods <a class=\"anchor\" id=\"3d\"></a>\n",
    "\n",
    "There are two basic options when running the pipeline in Python, and the differences arise in how they are configured to run.\n",
    "\n",
    "1. Using the 'call' method on a pipeline/step, and using parameter files to configure it (as done in previous examples). For example:    \n",
    "\n",
    "    `Detector1Pipeline.call('input_file.fits')` \n",
    "    \n",
    "    When the `.call` method is called on a pipeline instance, a new instance of that\n",
    "    pipeline is created internally. The values in the parameter file are set as\n",
    "    attributes on this new instance, the pipeline is run with these values, and\n",
    "    then it is disposed of and the final result is returned. This is the reccomended\n",
    "    way to run the pipeline since it is intended to be configured via parameter files.\n",
    "\n",
    "2. Configuring the pipeline/step insance directly by using its 'run' method. In this approach, the instance of the pipeline or step you create will have all parameters be the coded defaults, and to change them you set the attributes on the object directly.\n",
    "\n",
    "    `Detector1Pipeline.run('input_file.fits')`\n",
    "    \n",
    "    Or, equivalently\n",
    "    \n",
    "    `Detector1Pipeline('input_file.fits')`\n",
    "    \n",
    "    When 'pipe.run' or simply 'pipe()' are called, the instance you created is directly\n",
    "    used. So, any attributes set on that pipeline will be the ones used to direct the processing.\n",
    "    The additional setup done in `call` to set the parameter file as\n",
    "    attributes on the pipeline is not done, you will have to set each pipeline parameter\n",
    "    individually as an attribute on the pipeline instance you created before running it.\n",
    "\n",
    "It is reccomended that users stick to using the 'call' method which uses parameter files to set pipeline options, but configuring it directly and using `run` is also an option. \n",
    "\n",
    "### Example 3: Using `run` Instead of `call`  <a class=\"anchor\" id=\"3da\"></a>\n",
    "In this example, we will use the `run` method to run the `Image2Pipeline`. Parameters are set directly on the insance of `Image2Pipeline`, config files aren't used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:35,628 - stpipe.Image2Pipeline - INFO - Image2Pipeline instance created.\n",
      "2021-05-10 09:50:35,630 - stpipe.Image2Pipeline.bkg_subtract - INFO - BackgroundStep instance created.\n",
      "2021-05-10 09:50:35,633 - stpipe.Image2Pipeline.assign_wcs - INFO - AssignWcsStep instance created.\n",
      "2021-05-10 09:50:35,635 - stpipe.Image2Pipeline.flat_field - INFO - FlatFieldStep instance created.\n",
      "2021-05-10 09:50:35,637 - stpipe.Image2Pipeline.photom - INFO - PhotomStep instance created.\n",
      "2021-05-10 09:50:35,639 - stpipe.Image2Pipeline.resample - INFO - ResampleStep instance created.\n"
     ]
    }
   ],
   "source": [
    "from jwst.pipeline import Image2Pipeline\n",
    "\n",
    "# save_results has to be set here, because now we're calling this class directly \n",
    "pipe2 = Image2Pipeline(save_results=True)\n",
    "\n",
    "#result2 = pipe2.run('jw42424001001_01101_00001_nrca5_rate.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, identically, calling the pipeline obj directly which invokes the `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result2 = pipe2('jw42424001001_01101_00001_nrca5_rate.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Pipeline in Python <a class=\"anchor\" id=\"3e\"></a>\n",
    "\n",
    "\n",
    "### Setting Parameters <a class=\"anchor\" id=\"3f\"></a>\n",
    "\n",
    "As mentioned above, the parameter file is the basis of how pipelines/steps are configured - the parameter files in CRDS correspond to the 'best' set of parameters as chosen by the JWST instrument teams - but users are free to change any of these values when running the pipeline. There are a number of ways to do this when running the pipeline in Python.\n",
    "\n",
    "Let's go through a few examples of this. The output `rate` file from the last example can be run through the [Image2Pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html), which applies several calibtration steps including flat fielding and assigning a WCS. When this pipeline is run, the resulting data product is a `cal` file.\n",
    "\n",
    "#### Option 1: Using a Custom or Modified Parameter File (Reccomended)<a class=\"anchor\" id=\"3f1\"></a>\n",
    "The most straight forward way to configure the pipeline in Python is to change parameters within a parameter file, and pass this to the pipeline run with the `.call` method. Any CRDS parameter files will be overridden by those provided by the user.\n",
    "\n",
    "Again, begin by importing the desired pipeline or step, in this case `Image3Pipeline`, and creating an instance of it `pipe3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.pipeline import Image3Pipeline\n",
    "# pipe3 = Image3Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run it just like this without making any modifications, the corresponding parameter file will be obtained from CRDS and those values will be used. If you look at the logging output, you'll see one of the first lines indicates that the file `jwst_nircam_pars-tweakregstep_0006.asdf` is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3 = pipe3.call('jw42424001001_01101_00001_nrca5_cal.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cwd, we have the file 'my_custom_parfile_tweakregstep.asdf'. This file is in the exact same format as jwst_nircam_pars-tweakregstep_0006.asdf, but some of the values for the tweakreg step have been changed. We can direct Image3Pipeline to run with these values instead by setting the config_file argument to the path of our custom refence file, in this case just config_file = my_custom_parfile_tweakregstep.asdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3_myparfile = pipe3.call('jw42424001001_01101_00001_nrca5_cal.fits',\n",
    "                               # config_file='my_custom_parfile_tweakregstep.asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Setting Parameters as Attributes on a Pipeline/Step Directly<a class=\"anchor\" id=\"3f2\"></a>\n",
    "\n",
    "Setting parameters as attributes directly only works when using the `run` method on a pipeline/step instance. Because using `run` directly does not recognize any parameter files (custom or chosen by CRDS), ALL parameters must be set as attributes or else the hard coded defaults (which aren't necessarily within a reasonable range for the particular observing mode of your data) will be used. In this example, we will set most of the `tweakreg` parameters to the same values that are in the corresponding parameter file, but change `brightest` and `sigma` to a a different value. \n",
    "\n",
    "The following is equivalent to the example above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:44,722 - stpipe.Image3Pipeline - INFO - Image3Pipeline instance created.\n",
      "2021-05-10 09:50:44,724 - stpipe.Image3Pipeline.assign_mtwcs - INFO - AssignMTWcsStep instance created.\n",
      "2021-05-10 09:50:44,726 - stpipe.Image3Pipeline.tweakreg - INFO - TweakRegStep instance created.\n",
      "2021-05-10 09:50:44,729 - stpipe.Image3Pipeline.skymatch - INFO - SkyMatchStep instance created.\n",
      "2021-05-10 09:50:44,731 - stpipe.Image3Pipeline.outlier_detection - INFO - OutlierDetectionStep instance created.\n",
      "2021-05-10 09:50:44,734 - stpipe.Image3Pipeline.resample - INFO - ResampleStep instance created.\n",
      "2021-05-10 09:50:44,736 - stpipe.Image3Pipeline.source_catalog - INFO - SourceCatalogStep instance created.\n"
     ]
    }
   ],
   "source": [
    "pipe3 = Image3Pipeline()\n",
    "\n",
    "\n",
    "pipe3.brightest = 50\n",
    "pipe3.kernel_fwhm = 2.302\n",
    "pipe3.minobj = 15\n",
    "pipe3.nclip = 2\n",
    "pipe3.searchrad = 1.0\n",
    "pipe3.separation = 0.5\n",
    "pipe3.sigma = 3.0\n",
    "pipe3.snr_threshold = 5\n",
    "\n",
    "\n",
    "# pipe3.run('jw42424001001_01101_00001_nrca5_cal.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3: Setting Parameters via Dictionary when Using the `call` Method<a class=\"anchor\" id=\"3f3\"></a>\n",
    "\n",
    "It is possible to use the `call` method, which uses parameter files for configuration, and to change these values within a Python session without modifying or supplying any new parameter file. To do this, a nested dictionary specifiying any paramter overrides can be passed in. The following is also equivalent to the above examples.\n",
    "\n",
    "According to the parameter precedence rule, parameters in the CRDS-specified parameter file will be used, so we only have to override the exact parameters we wish to change from that file (while in the previous example, every parameter had to be set to change them from the coded default values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:46,871 - stpipe.Image3Pipeline - INFO - Image3Pipeline instance created.\n",
      "2021-05-10 09:50:46,873 - stpipe.Image3Pipeline.assign_mtwcs - INFO - AssignMTWcsStep instance created.\n",
      "2021-05-10 09:50:46,876 - stpipe.Image3Pipeline.tweakreg - INFO - TweakRegStep instance created.\n",
      "2021-05-10 09:50:46,878 - stpipe.Image3Pipeline.skymatch - INFO - SkyMatchStep instance created.\n",
      "2021-05-10 09:50:46,881 - stpipe.Image3Pipeline.outlier_detection - INFO - OutlierDetectionStep instance created.\n",
      "2021-05-10 09:50:46,883 - stpipe.Image3Pipeline.resample - INFO - ResampleStep instance created.\n",
      "2021-05-10 09:50:46,885 - stpipe.Image3Pipeline.source_catalog - INFO - SourceCatalogStep instance created.\n"
     ]
    }
   ],
   "source": [
    "pipe3 = Image3Pipeline()\n",
    "#pipe3.call(\"jw42424001001_01101_00001_nrca5_cal.fits\", \n",
    "#           steps={\"tweakreg\":{\"brightest\": 50, 'sigma': 3.0}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running a single step rather than a pipeline, the parameters can be set individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:48,532 - stpipe.TweakRegStep - INFO - TweakRegStep instance created.\n"
     ]
    }
   ],
   "source": [
    "from jwst.tweakreg import TweakRegStep\n",
    "\n",
    "tweakreg = TweakRegStep()\n",
    "\n",
    "#tweakreg.call(\"jw42424001001_01101_00001_nrca5_cal.fits\", sigma=3.0, brightest=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on Configuring Parameters in Python<a class=\"anchor\" id=\"3f4\"></a>\n",
    "\n",
    "The previous examples demonstrated the three possible ways of specifying pipeline parameters when running the pipeline in Pythom. It is reccomended that users use the first option, and specify any parameter overrides within a parameter file. \n",
    "\n",
    "Because there are multiple locations in which a parameter value may be specified (parameter file, coded defaults, setting the attributes on the pipe/step class directly, and command line paramater overriding which will be introduced later), the pipeline uses hierarchy rules to determine which value are used if they are specified in multiple locations.\n",
    "\n",
    "1. Value specified in command line, or set on class directly when using ``pipe.run()`` or `pipe()`.\n",
    "2. Value in user-provided parameter file.\n",
    "3. Value in CRDS parameter file.\n",
    "4. `Step`-coded default, determined by the parameter definition `Step.spec`\n",
    "\n",
    "According to these rules, if you specify both a custom parameter file AND provide a dictionary of parameter values when running the pipeline using `call`, the dictionary values will override any in the parameter file. Additionally, if you pass in an incomplete parameter file, the CRDS file will be used to set the other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Reference Files <a class=\"anchor\" id=\"3g\"></a>\n",
    "\n",
    "As shown above in example 1 (link), the `model.meta` (which is derived from the `fits` file header) contains paths to the reference files that will be used by the pipeline. Some users may want to substitute reference files - for example, to run with the old version of a particular file (not the entire set of files), or to use a custom made reference file. There are multiple options to do this when running the pipeline in Python.\n",
    "\n",
    "In these examples, we will run `Detector1Pipeline` on the `uncal.fits`, but substitute the CRDS-chosen dark reference file for our own, `my_dark.fits`.\n",
    "\n",
    "#### Option 1: Overriding Reference Files as an Argument to A Pipeline/Step<a class=\"anchor\" id=\"3g1\"></a>\n",
    "\n",
    "The simplest way to substitute a reference file is to provide it as an argument when creating the pipeline/step instance. By setting it this way, this information will also be passed on when running the pipeline with `call`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:52,081 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n",
      "2021-05-10 09:50:52,083 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2021-05-10 09:50:52,085 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2021-05-10 09:50:52,087 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2021-05-10 09:50:52,089 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2021-05-10 09:50:52,091 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2021-05-10 09:50:52,093 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2021-05-10 09:50:52,094 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2021-05-10 09:50:52,096 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2021-05-10 09:50:52,098 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2021-05-10 09:50:52,100 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2021-05-10 09:50:52,101 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2021-05-10 09:50:52,104 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2021-05-10 09:50:52,106 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2021-05-10 09:50:52,108 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2021-05-10 09:50:52,110 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2021-05-10 09:50:52,113 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n"
     ]
    }
   ],
   "source": [
    "pipe1_mydarkref = Detector1Pipeline()\n",
    "#pipe1_mydarkref('jw42424001001_01101_00001_nrca5_uncal.fits', dark_filename='my_dark.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Overriding Reference Files on a Pipeline/Step Directly<a class=\"anchor\" id=\"3g2\"></a>\n",
    "When calling the pipeline object directly using `pipe.run`, the desired reference file overrides can be set directly via the `override_<reffile>` attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:50:56,282 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n",
      "2021-05-10 09:50:56,284 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2021-05-10 09:50:56,286 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2021-05-10 09:50:56,288 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2021-05-10 09:50:56,290 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2021-05-10 09:50:56,292 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2021-05-10 09:50:56,294 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2021-05-10 09:50:56,295 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2021-05-10 09:50:56,297 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2021-05-10 09:50:56,299 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2021-05-10 09:50:56,301 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2021-05-10 09:50:56,303 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2021-05-10 09:50:56,304 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2021-05-10 09:50:56,306 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2021-05-10 09:50:56,308 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2021-05-10 09:50:56,310 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2021-05-10 09:50:56,312 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n"
     ]
    }
   ],
   "source": [
    "pipe1_mydarkref = Detector1Pipeline()\n",
    "pipe1_mydarkref.dark_current.override_dark = 'my_dark.fits'\n",
    "# result_mydarkref = pipe1_mydarkref('jw42424001001_01101_00001_nrca5_uncal.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipping Steps <a class=\"anchor\" id=\"3h\"></a>\n",
    "\n",
    "Sometimes you may want to run a pipeline, but omit certain steps contained within that pipeline. \n",
    "\n",
    "#### Option 1: Specifying Pipeline Steps to Skip within a Parameter File<a class=\"anchor\" id=\"3h1\"></a>\n",
    "\n",
    "To skip the `LinearityStep`, add the following to the `Detector1Pipeline` parameter file: \n",
    "\n",
    "steps:\n",
    "\n",
    "\\- class: jwst.linearity.linearity_step.LinearityStep\n",
    "\n",
    "  parameters:\n",
    "  \n",
    "       skip: true\n",
    "\n",
    "#### Option 2: Skipping Steps Directly when using 'run'<a class=\"anchor\" id=\"3h2\"></a>\n",
    "\n",
    "Just like setting parameteres or reference files, when calling a pipeline instance directly using the `run` method, directions to skip steps can be set as attributes. For example, to run `Detector1Pipeline` but skip the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 09:51:12,864 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n",
      "2021-05-10 09:51:12,866 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2021-05-10 09:51:12,868 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2021-05-10 09:51:12,870 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2021-05-10 09:51:12,871 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2021-05-10 09:51:12,873 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2021-05-10 09:51:12,875 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2021-05-10 09:51:12,877 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2021-05-10 09:51:12,879 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2021-05-10 09:51:12,880 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2021-05-10 09:51:12,882 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2021-05-10 09:51:12,883 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2021-05-10 09:51:12,885 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2021-05-10 09:51:12,888 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2021-05-10 09:51:12,890 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2021-05-10 09:51:12,892 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2021-05-10 09:51:12,894 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n"
     ]
    }
   ],
   "source": [
    "pipe_skipdark = Detector1Pipeline()\n",
    "pipe_skipdark.dark_current.skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Pipeline with the Command Line Interface (CLI) <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "The command line interface to the JWST pipeline is called `strun`. Everthing that is possible when running the pipeline in Python is also available via this interface - which one you use is up to personal preference. \n",
    "\n",
    "The basic formula to run the pipeline with the CLI is:\n",
    "\n",
    " `$ strun <pipeline_name, class_name, or parameter_file> <input_file>`\n",
    "\n",
    "\n",
    "The full class name (i.e `jwst.pipeline.Detector1Pipeline`) of a pipeline/step, or a parameter file (from which the pipeline/step is implied) is the first argument, followed by the path to the input data. Pipeline classes also have an “alias”, or short name, that can be used instead of the full class specification. For example, `jwst.pipeline.Detector1Pipeline` has the alias `calwebb_detector1` and can be run as\n",
    "### Example 3: Running a Full Pipeline using the CLI <a class=\"anchor\" id=\"4a\"></a>\n",
    "\n",
    "The following is the command line equivilent to [Example 1](#3b). This will run the `Detector1Pipeline` on the uncal.fits file with the CRDS designated parameter file, and all best reference files chosen by CRDS.\n",
    "\n",
    "In your shell:\n",
    "\n",
    "    >> $ strun jwst.pipeline.Detector1Pipeline jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "   \n",
    "    Or, so you don't have to type out the full class name, the alias name for this pipeline can be used.\n",
    "    \n",
    "    >> $ strun calwebb_detector1 jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "\n",
    "### Example 4: Running a Single Pipeline Step using the CLI <a class=\"anchor\" id=\"4b\"></a>\n",
    "\n",
    "The CLI can also be used to run a single pipeline step. The equivilant to [Example 2](#3c) would be:\n",
    "\n",
    "    >> $ strun jwst.linearity.LinearityStep jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "\n",
    "    \n",
    "### Configuring the Pipeline using the Command Line Interface <a class=\"anchor\" id=\"4c\"></a>\n",
    "### Setting Parameters <a class=\"anchor\" id=\"4d\"></a>\n",
    "\n",
    "Parameters can only be changed via parameter file when running with the command line interface. To use a custom parameter file, instead of the class name, use the path to the parameter file. For example:\n",
    "\n",
    "    >> strun my_custom_parfile_tweakregstep.asdf jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "#### Changing Reference Files <a class=\"anchor\" id=\"4e\"></a>\n",
    "\n",
    "To override a reference file, simply add a flag to the `strun` call. For example, to override the CRDS-chosed dark file with your own in the same working directory as the file.\n",
    "\n",
    "    >> $ strun calwebb_detector1 jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "      --steps.dark_current.override_dark='my_dark.fits'\n",
    "\n",
    "####  Skipping Steps <a class=\"anchor\" id=\"4f\"></a>\n",
    "\n",
    "Pipeline steps can also be skipped by adding a flag to the call. For example, to skip `LinearityStep` in the `Detector1Pipeline` - this is equivalent to the examples shown in the [Python section](#3h)\n",
    "    >> $ strun calwebb_detector1 jw42424001001_01101_00001_nrca5_uncal.fits\n",
    "    --steps.linearity.skip=True\n",
    "    \n",
    "#### Additional Command Line Functionality <a class=\"anchor\" id=\"4g\"></a>\n",
    "\n",
    "In addition to 'strun', the command line interface has tools to inspect avaiable pipelines and their parameters.\n",
    "\n",
    "To see what parameters are available for any given pipeline or step, use the -h option on strun. For example:\n",
    "\n",
    "    >> $ strun calwebb_detector1 -h\n",
    "    >> $ strun jwst.dq_init.DQInitStep -h\n",
    "    \n",
    "To see all available pipelines, steps, and their aliases:\n",
    "\n",
    "    >> $ stpipe list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
